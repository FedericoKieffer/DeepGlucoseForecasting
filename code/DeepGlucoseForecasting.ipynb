{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTztt9o01q1j"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4eQvLZ01ifA"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from google.colab import drive\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, LSTM, Concatenate, Dropout, Flatten\n",
    "from keras import regularizers \n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c8okR91F2cQS"
   },
   "source": [
    "## Mount Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FoyZZVvi2dfC"
   },
   "outputs": [],
   "source": [
    "drive.mount('/content/drive', force_remount=True)\n",
    "DataDir = '/content/drive/My Drive/DGF/'\n",
    "InjDir = DataDir + '/injections/'\n",
    "CgmDir = DataDir + '/cgm/'\n",
    "ChoDir = DataDir + '/cho/' \n",
    "imagespath = '/content/drive/My Drive/DGF/Results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yc4B4R5t1uy0"
   },
   "source": [
    "## Custom Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QC0gWGqp1qFR"
   },
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    " \n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('inj(t-%d)' %i), ('cho(t-%d)' %i), ('cgm(t-%d)' %i)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('inj(t)'), ('cho(t)'), ('cgm(t)')]\n",
    "        else:\n",
    "            names += [('inj(t+%d)' %i), ('cho(t+%d)' %i), ('cgm(t+%d)' %i)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P-yrybAu2iI5"
   },
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dcy7FdWJ2jUm"
   },
   "outputs": [],
   "source": [
    "ins = []\n",
    "cgm = []\n",
    "cho = []\n",
    "\n",
    "i = 1\n",
    "g = 1\n",
    "c = 1\n",
    "\n",
    "for signal in os.listdir(InjDir):\n",
    "    ins.append(scipy.io.loadmat(InjDir+str(i)+\".mat\"))\n",
    "    i += 1\n",
    "for signal in os.listdir(CgmDir): \n",
    "    cgm.append(scipy.io.loadmat(CgmDir+str(g)+\".mat\"))\n",
    "    g += 1\n",
    "for signal in os.listdir(ChoDir):    \n",
    "    cho.append(scipy.io.loadmat(ChoDir+str(c)+\".mat\"))\n",
    "    c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxceygUa2wKd"
   },
   "source": [
    "## Extract NpArrays from dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7cY3uEP2yra"
   },
   "outputs": [],
   "source": [
    "Np = 2\n",
    "injections = []\n",
    "cgms = []\n",
    "carbos = []\n",
    "\n",
    "for i in range (0, Np):\n",
    "    injection = ins[i]['injections'].flatten()\n",
    "    injections.append(injection)\n",
    "    glucose = cgm[i]['cgm'].flatten()\n",
    "    cgms.append(glucose)\n",
    "    carbo= cho[i]['cho'].flatten()\n",
    "    carbos.append(carbo)\n",
    "\n",
    "#Transform lists into 1D-NpArrays\n",
    "Injections = np.array(injections[0][1:])\n",
    "Cgms = np.array(cgms[0][1:])\n",
    "Carbos = np.array(carbos[0][1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JwPxyhL3YE9"
   },
   "source": [
    "## Transform sequences to supervised learning samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fom2H87C3cf9"
   },
   "outputs": [],
   "source": [
    "raw = DataFrame()\n",
    "raw['ob1'] = Injections\n",
    "raw['ob2'] = Carbos\n",
    "raw['ob3'] = Cgms\n",
    "values = raw.values\n",
    "values = values.astype('float32')\n",
    "#Specify the number of features and the 'look back' and 'prediction horizon' parameters (Only ph2 steps in the future are 'known', out of ph1)\n",
    "lb = 5\n",
    "ph1 = 5\n",
    "ph2 = 5 \n",
    "nbr_features = 3\n",
    "#Transform data into series for supervised learning\n",
    "data = series_to_supervised(values, lb, ph1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J50SyC8zFfiq"
   },
   "source": [
    "## Split samples in train, validation and test values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6KeWsC8MFlO1"
   },
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "values = data.values\n",
    "train_data_len = 24*60*14\n",
    "valid_data_len = 24*60*7\n",
    "train = values[:train_data_len, :]\n",
    "valid = values[train_data_len:(train_data_len+valid_data_len), :]\n",
    "test = values[(train_data_len+valid_data_len):, :]\n",
    "\n",
    "# split into input and outputs\n",
    "nbr_obs = nbr_features*lb\n",
    "x_train1, x_train2, y_train = train[:, :nbr_obs], np.delete(np.delete(np.delete(train, np.s_[(nbr_obs+2)::3], axis=1), np.s_[:nbr_obs], axis=1), np.s_[2*ph2:], axis=1), train[:, (nbr_obs+2)::3]\n",
    "x_valid1, x_valid2, y_valid = valid[:, :nbr_obs], np.delete(np.delete(np.delete(valid, np.s_[(nbr_obs+2)::3], axis=1), np.s_[:nbr_obs], axis=1), np.s_[2*ph2:], axis=1), valid[:, (nbr_obs+2)::3]\n",
    "x_test1, x_test2, y_test = test[:, :nbr_obs], np.delete(np.delete(np.delete(test, np.s_[(nbr_obs+2)::3], axis=1), np.s_[:nbr_obs], axis=1), np.s_[2*ph2:], axis=1), test[:, (nbr_obs+2)::3]\n",
    "\n",
    "# reshape input to be 3D of the format [samples, timesteps, features]\n",
    "x_train1 = x_train1.reshape((x_train1.shape[0], lb, nbr_features))\n",
    "x_train2 = x_train2.reshape((x_train2.shape[0], ph2, nbr_features-1))\n",
    "x_valid1 = x_valid1.reshape((x_valid1.shape[0], lb, nbr_features))\n",
    "x_valid2 = x_valid2.reshape((x_valid2.shape[0], ph2, nbr_features-1))\n",
    "x_test1 = x_test1.reshape((x_test1.shape[0], lb, nbr_features))\n",
    "x_test2 = x_test2.reshape((x_test2.shape[0], ph2, nbr_features-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l2rXOwHkcSd0"
   },
   "source": [
    "## Build the Deep GLucose Forcasting architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wBH_tAHgcWw3"
   },
   "outputs": [],
   "source": [
    "#Define the first RNN\n",
    "first_model = Sequential()\n",
    "first_model.add(LSTM(64, input_shape=(lb, nbr_features), return_sequences=False))\n",
    "\n",
    "#Define the second RNN\n",
    "second_model = Sequential()\n",
    "second_model.add(LSTM(64, input_shape=(ph2, nbr_features-1), return_sequences=False))\n",
    "\n",
    "#Concatenate the two models' outputs and pass it to the overall output layer\n",
    "MergedOutput = Concatenate()([first_model.output, second_model.output])\n",
    "MergedOutput = Dense(ph1, activation='relu')(MergedOutput)\n",
    "\n",
    "#Generate the overall model\n",
    "final_model = Model([first_model.input, second_model.input], MergedOutput)\n",
    "\n",
    "#Model summary\n",
    "final_model.summary()\n",
    "\n",
    "#Compile the model\n",
    "opt = optimizers.Adam(learning_rate=0.001)\n",
    "final_model.compile(optimizer=opt, loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9lkQ3Rpp7ZhT"
   },
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NlhPxhkO2WFJ"
   },
   "outputs": [],
   "source": [
    "#Train the model on the adult patient\n",
    "stopping = EarlyStopping(monitor='val_loss', patience=4)\n",
    "history = final_model.fit([x_train1, x_train2], y_train, batch_size=40, epochs=300, validation_data=([x_valid1, x_valid2], y_valid), callbacks=[stopping], verbose=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGOAFNfe2aLg"
   },
   "source": [
    "## Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qaPJHgwk2bm9"
   },
   "outputs": [],
   "source": [
    "models_dir = DataDir + '/Models/'\n",
    "\n",
    "def savemodel(model, name):\n",
    "    filename = os.path.join(models_dir, '%s.h5' %name)\n",
    "    final_model.save(filename)\n",
    "    print(\"\\nModel saved successfully on file %s\\n\" %filename)\n",
    "\n",
    "# Save the model\n",
    "savemodel(final_model, 'Full horizon 5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "svkT7NQgYH-3"
   },
   "source": [
    "## Plot training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xGGq-DWN3lUf"
   },
   "outputs": [],
   "source": [
    "#Plot training history\n",
    "plt.figure(figsize=(9,6))\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='valid')\n",
    "plt.legend()\n",
    "plt.xlabel('Epochs', fontdict=dict(size='12'))\n",
    "plt.ylabel('Loss (MSE)', fontdict=dict(size='12'))\n",
    "#plt.savefig('ph30.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGRDQ2bQe7tb"
   },
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Cp2CIM1e9c1"
   },
   "outputs": [],
   "source": [
    "#Calculate the model predictions\n",
    "predictions = final_model.predict([x_test1, x_test2])\n",
    "\n",
    "#Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wzAW_lwBI_NB"
   },
   "source": [
    "## Plot the predicted Glucose values vs the actual ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rarlOHSbF-M1"
   },
   "outputs": [],
   "source": [
    "#Create the true and predicted glucose histories\n",
    "Predictions=[]\n",
    "for i in range (0, len(predictions)):\n",
    "    Predictions.append(predictions[i][4])\n",
    "\n",
    "Validation=[]\n",
    "for i in range (0, len(y_test)):\n",
    "    Validation.append(y_test[i][4])\n",
    "\n",
    "#Convertion to Numpy arrays\n",
    "Predictions=np.array(Predictions)\n",
    "Validation=np.array(Validation)\n",
    "\n",
    "#Plot the results\n",
    "plt.figure(figsize=(14,7))\n",
    "plt.plot(Predictions[0:1440], 'r')\n",
    "plt.plot(Validation[0:1440], 'b')\n",
    "plt.xlabel('Time [min]', fontdict=dict(size='12'))\n",
    "plt.ylabel('Glucose Concentration [mg/dl]', fontdict=dict(size='12'))\n",
    "plt.legend(['Prediction', 'Actual'], loc='upper right')\n",
    "#plt.savefig('5_15_5min.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DeepGlucoseForecasting_ver1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
